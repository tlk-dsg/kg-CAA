2019 年最新颖出格的十篇 AI 论文

雷锋网 AI 科技评论按：前两天我们总结了 2019 年十大精彩 AI 学术论文，从学术价值的角度挑选了我们认为 2019 年里值得重读、值得纪念的机器学习论文。

在这篇文章里，雷锋网 AI 科技评论会盘点 2019 年出现的新颖有趣、挑战传统观念的十篇机器学习论文。其中有的论文的学术价值如何还有待商榷、有的论文甚至直接把前人的许多研究成果一把推翻，但这些论文都新意满满。这十篇论文刚好可以归为 5 个不同的主题，每个主题两篇。

AI + 更多领域、更多能力

OpenAI MuseNet

上榜理由：2019 年年初，在声称「GPT-2 过于危险，不能公布预训练模型」并引发大规模口水仗之后，OpenAI 觉得 GPT-2 的能力不止如此，他们尝试的下一个任务是安全且喜闻乐见的音乐生成。基于 GPT-2 编写的 MuseNet 模型继承并进一步加强了长序列生成能力，使用的训练数据是包含了 10 种不同乐器的、分类为多种不同曲风的数十万个 MIDI 文件，也就是数十万个乐曲。（MIDI 文件是乐谱的数字表示，可以指定乐器但不含有乐器的音色信息，学习 MIDI 是明确地让模型学习作曲风格。）

模型的效果是惊人的，OpenAI 不仅在直播中演示了许多风格各异、辨识度高、旋律自然的生成乐曲，他们还在介绍博客中提供了一个互动演示，可以从某首些知名乐曲中取一个小节作为开头，然后让模型以其他的风格续写，续写结果令人惊喜。还有好奇且有动手能力的网友们利用 OpenAI 提供的试验工具生成了更多乐曲，都印证了 MuseNet 确实有强大的作曲能力。

同期谷歌也在巴赫诞辰日做了一个模仿巴赫的作曲 AI（https://www.google.com/doodles/celebrating-johann-sebastian-bach），可以根据用户给出的音符，以巴赫的作曲风格增加和弦。这两个音乐 AI 的区别，除了巴赫 AI 只掌握巴赫的曲风之外，还在于巴赫 AI 是在已经给出的小节中继续增加音符形成和弦，而 OpenAI 的 MuseNet 是向后续写更多小节。

博客地址：openai.com/blog/musenet

详细阅读：https://www.leiphone.com/news/201904/ZCIbdikWj3cGViEY.html

Newton vs the machine:solving the chaotic three-body problem using deep neural networks

深度神经网络求解三体运动问题

上榜理由：三体运动问题没有解析解早有定论，所以这篇论文公开之后也引发了一些批评，毕竟论文只是尝试了极为简化的情况（三个质量相等、初始速度为零的粒子在同一个平面内）、只是做到了接近的数值解就拿出来张扬，而且还宣称比计算精确解的专业软件快十万倍，对网络的能力有夸大吹捧之嫌。

这篇论文也有积极的一面。以深度学习为代表的机器学习手段确实在各种端到端的学习预测任务中得到了越来越多的运用，但其实深度学习的能力也不仅如此，它还可以在许多领域的更多任务中发挥作用，正如三体运动这样的复杂问题中我们缺少可以快速计算近似解的工具。

论文地址：https://arxiv.org/abs/1910.07291

解读文章：https://www.yanxishe.com/blogDetail/14946



深入认识我们习以为常的现象

ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness ( ICLR 2019 )

在 ImageNet 上训练的 CNN 会带有纹理偏倚；增加形状偏倚可以提高准确度和鲁棒性

上榜理由：现代 CNN 网络有很强的特征表示学习能力，能在 ImageNet 上得到很高的识别准确率。不过，不断改进网络架构、不断刷分的人多，探究 CNN 到底学到了怎么样的特征表示的人少。按理说，对象识别的边界和纹理之争早就存在，不过我们终于还是在 2019 年看到了针对性的研究论文。

这篇论文中的实验表明，在 ImageNet 上训练的 CNN 网络在对象识别中依赖纹理远多于依赖形状；这其实和人类对自己的识别模式的认知有很大区别，也和我们对 CNN 工作方式的理解有所不同。作者们的结论有充分的实验支持，他们甚至用生成的风格转换数据集训练了依赖形状更多的 CNN，这样的 CNN 在识别准确率和鲁棒性方面都有提高。这篇论文被 ICLR 2019 接收。

论文地址：https://arxiv.org/abs/1811.12231

Deep Double Descent: Where Bigger Models and More Data Hurt

研究深度双波谷：更大的模型和更多的数据有时会产生负面作用

上榜理由：2019 年中，包括 OpenAI 在内的一批学者「老调重谈」地再次讨论起模型复杂度和过拟合的问题来。机器学习界流传已久的观念是，随着模型的复杂度增大（学习能力提高），模型总能得到更小的训练误差，但测试误差和训练误差的差会越来越大（出现过拟合）；所以模型复杂度不能太低、也不能太高，我们需要找到相对平衡的那个点。（上面的 U 型图）

但这两年来，一大批超级大、超级复杂的模型用实际行动表明了训练误差和测试误差都还可以一同持续下降。所以这次讨论形成的新共识是，我们需要在 U 型图的右侧继续扩充，用来表示现代的、大容量的深度学习模型在大小超过某个阈值之后，越大的模型会具有越好的泛化性。这样，整张图就形成了双波谷的样子（下图） —— 也就是说，当你的模型大小很不幸地落在中间的波峰的时候，你就会遇到模型越大、 数据越多反而表现越差的尴尬情境。